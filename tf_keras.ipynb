{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potřebné knihovny\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Převedení obrázku na potřebné rozlišení\n",
    "\n",
    "---\n",
    "\n",
    "Některé obrázky s captchou nemají potřebné rozlišení 200x50 pixelů. Takové snímky je potřeba upravit.\n",
    "\n",
    "<br>\n",
    "\n",
    "Třída `Picture` slouží pouze pro inicializaci existujících obrázků.\n",
    "\n",
    "<br>\n",
    "\n",
    "Třída `Modified` dědí z třídy `Picture` její instanční atributy a slouží pro modifikaci stávajících parametrů a vytvoření nového obrázku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Picture:\n",
    "    def __init__(self, path: str, name: str, width: int, height: int) -> None:\n",
    "        self.path = path\n",
    "        self.name = name\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "    def initiate_image(self, imread_flag:int) -> np.ndarray:\n",
    "        return cv2.imread(self.path, imread_flag)\n",
    "        \n",
    "    def get_dimension_of_image(self, img: np.ndarray) -> tuple:\n",
    "        return img.shape\n",
    "    \n",
    "    def save_image(self, img: np.ndarray) -> None:\n",
    "        cv2.imwrite(self.name, img)\n",
    "\n",
    "\n",
    "class Modifier(Picture):\n",
    "    def is_resolution_same(self, img: np.ndarray) -> bool:\n",
    "        original_width, original_height, *number = self.get_dimension_of_image(img)\n",
    "        return (original_width, original_height) == (self.width, self.height)\n",
    "    \n",
    "    def resize_image(self, img: np.ndarray) -> np.ndarray:\n",
    "        return cv2.resize(\n",
    "            img,\n",
    "            (self.height, self.width),\n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing of class instance with example 'nh4ut.png'\n",
    "testing_png = Modifier(\"captchas/qft8t.png\", \"qft8t_resized.png\", 50, 200)\n",
    "image = testing_png.initiate_image(cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if testing_png.is_resolution_same(image):\n",
    "    print(f\"Resolution is already correct {testing_png.get_dimension(image)}\")\n",
    "else:\n",
    "    resized = testing_png.resize_image(image)\n",
    "    testing_png.save_image(resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odstranění šumu a přebytečných čar z obrázku\n",
    "\n",
    "---\n",
    "\n",
    "Některé z obrázků mohou obsahovat přidaný šum teček a jiných patvarů, které je nutné zjemnit pro následné vyhodnocování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "class Erosion(Picture):\n",
    "    def apply_adaptive_thresholding(self):\n",
    "        image = self.initiate_image(cv2.IMREAD_GRAYSCALE)\n",
    "        return cv2.adaptiveThreshold(\n",
    "            image,\n",
    "            255,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,  # ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "            cv2.THRESH_BINARY,\n",
    "            199,\n",
    "            5\n",
    "        )\n",
    "        \n",
    "    def dilate_image(self, threshold, num_of_iteration: int = 1):\n",
    "        kernel = np.ones((3,1), np.uint8)\n",
    "#         img_erosion = cv2.erode(threshold, kernel, iterations=num_of_iteration)\n",
    "        return cv2.dilate(threshold, kernel, iterations=num_of_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing of class instance with example 'nh4ut.png'\n",
    "erosion = Erosion(\"qft8t_resized.png\", \"qft8t_clean.png\", 50, 200)\n",
    "threshold = erosion.apply_adaptive_thresholding()\n",
    "result = erosion.dilate_image(threshold)\n",
    "plt.imshow(result) \n",
    "erosion.save_image(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predikce hodnot\n",
    "\n",
    "---\n",
    "\n",
    "Nachystání modelu (poznámky nejsou kompletní)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_captcha():\n",
    "    run_recognition()\n",
    "\n",
    "    \n",
    "def run_recognition():\n",
    "    symbols = string.ascii_lowercase + string.digits\n",
    "    number_of_values = len(symbols)\n",
    "    image_shape = (50, 200, 1)\n",
    "    model = create_model(image_shape, number_of_values)\n",
    "    X, y = preprocess_data(symbols, number_of_values)\n",
    "    \n",
    "    X_train, y_train = X[:970], y[:, :970]\n",
    "    X_test, y_test = X[970:], y[:, 970:]\n",
    "    \n",
    "#     model.summary()\n",
    "\n",
    "    hist = model.fit(\n",
    "        X_train,\n",
    "        [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]],\n",
    "        batch_size=32,\n",
    "        epochs=30,\n",
    "        verbose=1, \n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "     # evaluate the precission\n",
    "#     score= model.evaluate(\n",
    "#         X_test,\n",
    "#         [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]],\n",
    "#         verbose=1\n",
    "#     )\n",
    "#     print('Test Loss and accuracy:', score)\n",
    "    \n",
    "    # test some captcha samples \n",
    "    return model\n",
    "\n",
    "#     model.evaluate(X_test, [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]])\n",
    "#     print(predict(model, symbols, './solver/data/samples/3dgmf.png'))  # 3dgmf\n",
    "#     print(predict(model, symbols, './solver/data/samples/5gcd3.png'))  # 5gcd3\n",
    "#     print(predict(model, symbols, './solver/data/samples/xymfn.png'))  # xynfn\n",
    "#     print(predict(model, symbols, './solver/data/samples/yyn57.png'))  # yyn57\n",
    "#     print(predict(model, symbols, './solver/data/samples/e43ym.png'))  # e43ym\n",
    "#     print(predict(model, symbols, '4neuf_clean.png'))  # ?\n",
    "\n",
    "\n",
    "def create_model(img_shape: tuple, num_of_vals: int):\n",
    "    \"\"\"\n",
    "    Links:\n",
    "    - https://keras.io/api/layers/core_layers/input/\n",
    "    - https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "    - https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
    "    - https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
    "    \n",
    "    Description:\n",
    "    1. Input() is used to instantiate a Keras tensor,\n",
    "    2. 2D convolution layer (e.g. spatial convolution over images).\n",
    "    3. Max pooling operation for 2D spatial data.\n",
    "    4. Batch normalization applies a transformation that maintains\n",
    "       the mean output close to 0 and the output standard\n",
    "       deviation close to 1.\n",
    "    5. Compile model and return it.\n",
    "    \"\"\"\n",
    "    image = layers.Input(shape=img_shape)\n",
    "    \n",
    "    mp3 = process_image_through_convulations(image)\n",
    "    flattened_vectors = get_flattened_vector(mp3, num_of_vals)\n",
    "\n",
    "    model = Model(image, flattened_vectors)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def process_image_through_convulations(img_shape: tuple):\n",
    "    convolution_1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img_shape)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(convolution_1)\n",
    "    convolution_2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(convolution_2)\n",
    "    convolution_3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    b_normalization = layers.BatchNormalization()(convolution_3)\n",
    "    return layers.MaxPooling2D(padding='same')(b_normalization)\n",
    "    \n",
    "\n",
    "def adjust_layer(flat, num_of_vals):\n",
    "    dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "    drop = layers.Dropout(0.5)(dens1)\n",
    "    return layers.Dense(num_of_vals, activation='sigmoid')(drop)\n",
    "\n",
    "    \n",
    "def get_flattened_vector(mp, num_of_vals):\n",
    "    \"\"\"\n",
    "    Links:\n",
    "    - https://keras.io/api/layers/regularization_layers/dropout/\n",
    "    - https://keras.io/api/layers/core_layers/dense/\n",
    "    \n",
    "    Description:\n",
    "    1. The Dropout layer randomly sets input units to 0 with\n",
    "       a frequency of rate at each step during training time,\n",
    "       which helps prevent overfitting. Inputs not set to 0\n",
    "       are scaled up by 1/(1 - rate) such that the sum over\n",
    "       all inputs is unchanged.\n",
    "    \"\"\"\n",
    "    flattened = layers.Flatten()(mp)\n",
    "    return [\n",
    "        adjust_layer(flattened, num_of_vals)\n",
    "        for _ in range(5)\n",
    "    ]\n",
    "\n",
    "\n",
    "def preprocess_data(symbols: str, symbols_len: int):\n",
    "    rel_path = \"./solver/data/samples\"\n",
    "    number_of_samples = len(os.listdir(rel_path))\n",
    "    X = np.zeros((number_of_samples, 50, 200, 1))\n",
    "    y = np.zeros((5, number_of_samples, symbols_len))\n",
    "    \n",
    "    for index, picture in enumerate(os.listdir(rel_path)):\n",
    "        img = cv2.imread(os.path.join(rel_path, picture), cv2.IMREAD_GRAYSCALE)\n",
    "        captcha = os.path.splitext(picture)[0]\n",
    "        \n",
    "        if len(captcha) < 6:\n",
    "            img = img / 255.0\n",
    "            img = np.reshape(img, (50, 200, 1))\n",
    "            \n",
    "            targets = np.zeros((5, symbols_len))\n",
    "            \n",
    "            for nest_index, sign in enumerate(captcha):\n",
    "                sign_index = symbols.find(sign)\n",
    "                targets[nest_index, sign_index] = 1\n",
    "            \n",
    "            X[index] = img\n",
    "            y[:, index] = targets\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def predict(model, symbols: str, filepath: str) -> str:\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is not None:\n",
    "        img = img / 255.0\n",
    "    else:\n",
    "        print(\"Not detected\")\n",
    "        \n",
    "    res = np.array(model.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 36))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    \n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        #probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    \n",
    "    for l in l_ind:\n",
    "        \n",
    "        capt += symbols[l]\n",
    "    return capt #, sum(probs) / 5\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recognize_captcha()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
